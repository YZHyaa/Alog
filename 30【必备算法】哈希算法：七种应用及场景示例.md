在文章开头先看看哈希算法到底什么？

* 定义：将任意长度的二进制值串映射为**固定长度**的二进制值串，这个映射的规则就是哈希算法。通过原始数据映射之后得到的二进制值串就是**哈希值**

* 需要满足的四点要求：

  * 从哈希值不能反向推导出原始数据（所以哈希算法也叫**单向**哈希算法）；
  * 对输入数据非常**敏感**，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同；
  * 散列**冲突**的概率要很小，对于不同的原始数据，哈希值相同的概率非常小；
  * 哈希算法的执行效率要尽量**高效**，针对较长的文本，也能快速地计算出哈希值

* 举例：MD5

  * MD5(" 今天说哈希算法！") = 425f0d5a917188d2c3c3dc85b5e4f2cb
   * MD5("jiajia") = cd611a31ea969b908932d44d126d195b

 哈希算法要处理的文本可能是各种各样的。比如，对于非常长的文本，如果哈希算法的计算时间很长，那就只能停留在理论研究的层面，很难应用到实际的软件开发中。比如，我们把今天这篇包含 4000 多个汉字的文章，用 MD5 计算哈希值，用不了 1ms 的时间。

## 1.开发应用一：安全加密

说到哈希算法的应用，最先想到的应该就是安全加密。最常用于加密的哈希算法是 MD5（MD5 Message-Digest Algorithm，MD5 消息摘要算法）和SHA（Secure Hash Algorithm，安全散列算法）。除了这两个之外，当然还有很多其他加密算法，比如DES（Data Encryption Standard， 数据加密标准）、AES（Advanced Encryption Standard，高级加密标准）。

除了前面说到的哈希算法四点要求，对用于加密的哈希算法来说，有两点格外重要：

* 第一点： **很难根据哈希值反向推导出原始数据**。加密的目的就是防止原始数据泄露，所以很难通过哈希值反向推导原始数 据，这是一个最基本的要求。

* 第二点： **散列冲突的概率要很小**。实际上，不管是什么哈希算法，我们只能尽量减少碰撞冲突的概率，理论上是**没办法做到完全不冲突的**。

  * 这里就基于组合数学中一个非常基础的理论，**鸽巢原理**（也叫抽屉原理）。这个原理本身很 简单，它是说，如果有 10 个鸽巢，有 11 只鸽子，那肯定有 1 个鸽巢中的鸽子数量多于 1 个，换句话说就是，肯定有 2 只鸽子在 1 个鸽巢内。
  * 我们知道，哈希算法产生的哈希值的长度是固定且有限的。比如前面举的 **MD5 的例子**，哈希值是固定的 128 位二进制串，能表示的数据是有限的，最多能表示 2^128 个数据，而 我们要哈希的数据是无穷的。基于鸽巢原理，如果我们对 2^128+1 个数据求哈希值，就必然会存在哈希值相同的情况。所以，一般情况下，哈希值越长的哈希算法， 散列冲突的概率越低。
 
 	
即便哈希算法存在散列冲突的情况，但是因为**哈希值的范围很大，冲突的概率极低**， 所以相对来说还是很难破解的。像 MD5，有 2^128 个不同的哈希值，这个数据已经是一 个天文数字了，所以散列冲突的概率要小于 1/2^128。如果我们拿到一个 MD5 哈希值，希望通过毫无规律的穷举的方法，找到跟这个 MD5 值相 同的另一个数据，那耗费的时间应该是个天文数字。

所以，**即便哈希算法存在冲突，但是在有限的时间和资源下，哈希算法还是被很难破解的**。
```
2^128=340282366920938463463374607431768211456
```

除此之外，**没有绝对安全的加密。越复杂、越难破解的加密算法，需要的计算时间也越长**。 比如 SHA-256 比 SHA-1 要更复杂、更安全，相应的计算时间就会比较长。密码学界也一 直致力于找到一种快速并且很难被破解的哈希算法。我们在实际的开发过程中，也需要权衡 破解难度和计算时间，来决定究竟使用哪种加密算法。

## 2.开发应用二：唯一标识

```
哈希算法可以对大数据做信息摘要，通过一个较短的二进制编码来 表示很大的数据。
```

举一个例子。如果要在**海量的图库中，搜索一张图是否存在**，我们不能单纯地用图片的元信息（比如图片名称）来比对，因为有可能存在名称相同但图片内容不同，或者名称不 同图片内容相同的情况。那我们该如何搜索呢？

我们知道，任何文件在计算中都可以表示成二进制码串，所以，比较笨的办法就是，拿**要查找的图片的二进制码串与图库中所有图片的二进制码串一一比对**。如果相同，则说明图片在 图库中存在。但是，每个图片小则几十 KB、大则几 MB，转化成二进制是一个非常长的 串，比对起来非常耗时。有没有比较快的方法呢？

我们可以**给每一个图片取一个唯一标识**，或者说信息摘要。比如，我们可以从图片的**二进制码串开头取 100 个字节，从中间取 100 个字节，从最后再取 100 个字节**，然后将这 300 个字节放到一块，通过哈希算法（比如 MD5），得到一个哈希字符串，用它作为图片的唯 一标识。通过这个唯一标识来判定图片是否在图库中，这样就可以减少很多工作量。

如果还想继续提高效率，我们可以把**每个图片的唯一标识，和相应的图片文件在图库中的路径信息，都存储在散列表中**。当要查看某个图片是不是在图库中的时候，我们先通过哈希算法对这个图片取唯一标识，然后在散列表中查找是否存在这个唯一标识。

如果不存在，那就说明这个图片不在图库中。如果存在，我们再通过散列表中存储的文件路 径，获取到这个已经存在的图片，跟现在要插入的图片做全量的比对，看是否完全一样。如 果一样，就说明已经存在；如果不一样，说明两张图片尽管唯一标识相同，但是并不是相同 的图片。

## 3.开发应用三：数据校验

我们知道，BT 下载的原理是基于 P2P 协议的。我们从多个机器上并行下载一个 2GB 的电影，这个电影文件可能会被分割成很多文件块（比如可以分成 100 块，每块大约 20MB）。等所有的文件块都下载完成之后，再组装成一个完整的电影文件就行了。

我们知道，网络传输是不安全的，下载的文件块有可能是被宿主机器恶意修改过的，又或者 下载过程中出现了错误，所以下载的文件块可能不是完整的。如果我们没有能力检测这种恶 意修改或者文件下载出错，就会导致最终合并后的电影无法观看，甚至导致电脑中毒。现在 的问题是，**如何来校验文件块的安全、正确、完整呢？**

具体的 BT 协议很复杂，校验方法也有很多，下面说其中的一种思路。

我们通过哈希算法，对 100 个文件块分别取哈希值，并且保存在种子文件中。我们在前面 讲过，**哈希算法有一个特点，对数据很敏感。只要文件块的内容有一丁点儿的改变，最后计算出的哈希值就会完全不同**。所以，当文件块下载完成之后，我们可以通过相同的哈希算法，对下载好的文件块逐一求哈希值，然后跟种子文件中保存的哈希值比对。如果不同，说 明这个文件块不完整或者被篡改了，需要再重新从其他宿主机器上下载这个文件块。

## 4.开发应用四：散列函数

散列函数是设计一个散列表的关键。它直接决定了散列冲突的概率和散列表的性能。不过，相对哈希算法的其他应用，**散列函数对于散列算法冲突的要求要低很多**。 即便出现个别散列冲突，只要不是过于严重，我们都可以通过开放寻址法或者链表法解决。

不仅如此，散列函数对于散列算法计算得到的值，**是否能反向解密也并不关心**。散列函数中用到的散列算法，**更加关注散列后的值是否能平均分布**，也就是，一组数据是否能均匀地散 列在各个槽中。除此之外，**散列函数执行的快慢**，也会影响散列表的性能，所以，散列函数 用的散列算法一般都比较简单，比较追求效率。

## 5.架构应用五：负载均衡

我们知道，负载均衡算法有很多，比如轮询、随机、加权轮询等。那如何才能实现一个会话粘滞（session sticky）的负载均衡算法呢？也就是说，我们**需要在同一个客户端上，将一次会话中的所有请求都路由到同一个服务器上。**

直接的方法就是，**维护一张映射关系表**，这张表的内容是客户端 IP 地址或者会话 ID 与 服务器编号的映射关系。客户端发出的每次请求，都要先在映射表中查找应该路由到的服务器编号，然后再请求编号对应的服务器。这种方法简单直观，但也有几个弊端：
  * 如果客户端很多，映射表可能会很大，比较浪费内存空间；
  * 客户端下线、上线，服务器扩容、缩容都会导致映射失效，这样维护映射表的成本就会很大；

还可以通过哈希算法，**对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号**。
  * 哈希算法可以保证每个客户端的哈希值不同，达到负载均衡效果
  * 取模可以把同一个 IP 过来的所有请求，都路由到同一个后端服务器上

## 6.架构应用六：数据分片

哈希算法还可以用于数据的分片，这里有两个例子。

---
示例一：如何**统搜索关键出现的次数**？假如我们有 1T 的日志文件，这里面记录了用户的搜索关键词，我们想要快速统计出每个关 键词被搜索的次数，该怎么做呢？

 我们来分析一下。这个问题有两个难点。第一个是搜索日志很大，没办法放到一台机器的内存中；第二个难点是，如果只用一台机器来处理这么巨大的数据，处理时间会很长。
 
 针对这两个难点，我们可以**先对数据进行分片，然后采用多台机器处理的方法**，来提高处理速度。
   * 为了提高处理的速度，我们用 **n 台机器并行处理**。
    * 我们从搜索记录的日志文件中，依次读出每个**搜索关键词，并且通过哈希函数计算哈希值，然后再跟 n 取模**，终得到的值，就是应该被分配到的机器编号。
 	
这样，哈希值相同的搜索关键词就被分配到了同一个机器上。也就是说，同一个搜索关键词会被分配到同一个机器上。每个机器会分别计算关键词出现的次数，后合并起来就是终的结果。实际上，这里的处理过程也是 MapReduce 的基本设计思想。

----
示例二：如何快速判断**图片是否在图库中**？假设现在我们的图库中有 **1 亿张图片**

很显然，在**单台机器上构建散列表是行不通**的。因为单台机器的内存有限，而 1 亿张图片构建散列表显然远远超过了单台机器的内存上限。我们同样可以对**数据进行分片，然后采用多机处理**。
   1. 准备 **n 台机器**，让每台机器只维护某一**部分图片对应的散列表**
  2. 每次从图库中读取一个图片，**计算唯一标识，然后与机器个数 n 求余取模**，得到的值就对应要分配的机器编号
  3. 然后将这个图片的唯一标识和图片路径发往对应的机器**构建散列表**
    3. 当我们要判断一个图片是否在图库中的时候，我们通过同样的哈希算法，**计算这个图片的唯一标识，然后与机器个数 n 求余取模**。假设得到的值是 k，那就去编号 k 的机器构建的**散列表中查找**

现在，我们来估算一下，给这 1 亿张图片构建散列表大约需要**多少台机器**。散列表中每个数据单元包含两个信息，哈希值和图片文件的路径。
* 假设我们通过 MD5 来计 算哈希值，那长度就是 128 比特，也就是 16 字节。
* 文件路径长度的上限是 256 字节，我 们可以假设平均长度是 128 字节。如果我们用链表法来解决冲突，那还需要存储指针，指针只占用 8 字节。

所以，散列表中每个数据单元就占用 152 字节（这里只是估算，并不准确）。假设一台机器的内存大小为 2GB，散列表的装载因子为 0.75，那一**台机器可以给大约 1000 万（2GB*0.75/152）张图片构建散列表**。所以，如果要对 1 亿张图片构建索引，需要大约十几台机器。

实际上，针对这种海量数据的处理问题，我们都可以采用多机分布式处理。借助这种分片的思路，可以突破单机内存、CPU 等资源的限制。

## 7.架构应用七：一致性哈希

问题：在分布式缓存的情景下，缓存按上述哈希算法进行分机存储，若其中一台服务器宕机，或者整体要缩容扩容。虽然hash值还是不变，但取模的服务器数改变了，因此计算出的对应服务器已经错误了。造成的结果是，所有的数据请求都会穿透缓存，直接去请求数据库。这样就 可能发生雪崩效应，压垮数据库。

==》**[一致性哈希](https://www.zsythink.net/archives/1182)**

**假设我们有 k 个机器，数据的哈希值的范围是 [0, MAX]**

**==》将整个范围划分成 m 个小区间（m 远大于 k）去直接管理每个客户端**

**==》每个机器负责 m/k 个小区间**

**==》若集群变动只用迁移少量区间即可**

* 服务器定位：确定每个管理哪些区间，原来的分片算法并无此步。注：这里的2^32是因为IPV4，32位的IP断，相当于根据IP断进行分区管理
  ![在这里插入图片描述](https://img-blog.csdnimg.cn/20201018203830385.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzNTkyNw==,size_16,color_FFFFFF,t_70#pic_center)
* 客户端定位：定位不依赖于服务器数量，而是看其处于哪个小区间

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/20201018204007888.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzNTkyNw==,size_16,color_FFFFFF,t_70#pic_center)


* 区间迁移：若有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。这样，既不用全部重新哈希、搬移数据，也保持了各个机器上数据数量的均衡。
	![在这里插入图片描述](https://img-blog.csdnimg.cn/20201018204054178.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzNTkyNw==,size_16,color_FFFFFF,t_70#pic_center)






